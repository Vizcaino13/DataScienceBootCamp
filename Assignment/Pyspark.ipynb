{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Apache spark\n",
        "\n",
        "It runs workloads 100X faster, it is bascially to work with big data\n",
        "\n",
        "it is faster than Map reduce (which i think is hadoop)\n",
        "\n",
        "you canb write an application in java, scala, python or r\n",
        "\n",
        "Handy because if you have a huge amount of data such as 1.8 gb ram, this helps to preprocess the data in distriubuted systemns which is multiple systems that can run this data processing.\n",
        "\n",
        "spark can run on hadoop and other cloud based services and it runs on clustermode which is a distrubuted mode\n",
        "\n",
        "pyspark is Apachespark api for python\n",
        "\n",
        "pyspark gives dataframes kinda like pandasa but not the sane\n",
        "\n",
        "\n",
        "\n",
        "Apache spark  MLlib which will help prefom machine learnming algorthiom task such as regression, clustering etc"
      ],
      "metadata": {
        "id": "HF6OVkNeIp3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing PySpark\n"
      ],
      "metadata": {
        "id": "2LP5-wzsKRtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing PySpark, you would typically proceed with importing necessary modules, creating a SparkSession, and writing your Spark application logic."
      ],
      "metadata": {
        "id": "BQTEbjZWNda_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "\n",
        "\n",
        "#PySpark is the Python API for Apache Spark, which is a fast and general-purpose cluster computing system.\n",
        "#PySpark allows you to write Spark applications using Python, making it more accessible to Python developers."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K84USAFSKXvf",
        "outputId": "e2066921-8059-44ad-e248-9ebadf3f7dfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n"
      ],
      "metadata": {
        "id": "GE5r2JOsKa1a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(\"/content/test1.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "F9sonR4qLMJU",
        "outputId": "19bec916-7292-46ec-8e1c-5da9f98c02cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Name  age  Experience  Salary\n",
              "0      Krish   31          10   30000\n",
              "1  Sudhanshu   30           8   25000\n",
              "2      Sunny   29           4   20000\n",
              "3       Paul   24           3   20000\n",
              "4     Harsha   21           1   15000\n",
              "5    Shubham   23           2   18000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ebfa612-a2ea-4a15-a526-b595f993380c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>age</th>\n",
              "      <th>Experience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Krish</td>\n",
              "      <td>31</td>\n",
              "      <td>10</td>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sudhanshu</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Paul</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Harsha</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Shubham</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>18000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ebfa612-a2ea-4a15-a526-b595f993380c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ebfa612-a2ea-4a15-a526-b595f993380c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ebfa612-a2ea-4a15-a526-b595f993380c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2db99f97-c3f0-48cb-9b51-370f20f97ef9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2db99f97-c3f0-48cb-9b51-370f20f97ef9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2db99f97-c3f0-48cb-9b51-370f20f97ef9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating a spark session"
      ],
      "metadata": {
        "id": "3FZoN5juM2U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#This line imports the SparkSession class,\n",
        "#which is a fundamental entry point to interact with Spark and enables the creation of DataFrames and executing SQL queries"
      ],
      "metadata": {
        "id": "FidFqbGBMTfx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a Spark session using the SparkSession class with the specified application name 'Practise'\n",
        "\n",
        "spark= SparkSession.builder.appName('Practise').getOrCreate()\n",
        "\n",
        "#SparkSession.builder: This is a builder pattern used to configure the Spark session.\n",
        "\n",
        "#.appName('Practise'): Sets the name of the Spark application to 'Practise'. The application name is a user-defined string that helps identify your Spark application when monitoring it in the Spark UI.\n",
        "\n",
        "#.getOrCreate(): This method either retrieves an existing Spark session if one exists or creates a new one if none is found."
      ],
      "metadata": {
        "id": "eo-d30xlMcmb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a Spark session named 'Practise' was created\n",
        "\n",
        "#SparkSession - in-memory: This line indicates that your Spark session is configured to use an in-memory mode. In-memory mode means that Spark will store and process data in memory, which can lead to faster data processing compared to disk-based storage.\n",
        "\n",
        "#SparkContext: This is the main entry point for Spark functionality. It provides the connection to the Spark cluster. In a Spark session, the SparkContext is created automatically, and you can access it through the spark.sparkContext attribute.\n",
        "\n",
        "#Spark UI: The Spark UI is a web-based user interface that provides insights into the status and performance of your Spark application. You can usually access the Spark UI in a web browser using a URL provided in the console log.\n",
        "\n",
        "#Master local[*]: This specifies the Spark master URL. In your case, it is set to run locally (local) using all available cores ([*]). This is suitable for local development and testing.\n",
        "\n",
        "#AppName Practise: The name of your Spark application, which you set as 'Practise' when creating the Spark session.\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "z_64FZ2pMqnw",
        "outputId": "bdfb06ab-5218-4f9a-fa77-b3c0f07d8d7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d4b04d7d8d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7fa3f43e8b55:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark= spark.read.csv('test1.csv')"
      ],
      "metadata": {
        "id": "UuNONanBMuiV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark\n",
        "#the column names are cmoning out as c0 , c1 etc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4qy1XVcP1d1",
        "outputId": "8c92fbe2-e2c6-4bf2-9f5e-e49bb1f47b47"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn0JQMFJPovk",
        "outputId": "9123496e-0e12-4cb7-daa6-69825d73a2e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|      _c0|_c1|       _c2|   _c3|\n",
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the dataframe\n",
        "#to change the columns to its actual names do this\n",
        "df_pyspark= spark.read.option('header', 'true').csv('test1.csv')\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UUhYzYCPse5",
        "outputId": "b587620d-f670-40f2-8d4a-91b2292697ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here you can see that this is a different dataframe not a pandas one\n",
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO-MAIkKQfpR",
        "outputId": "064a9caa-b68b-487b-b546-d6395d1fd192"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is like df.info\n",
        "#checking the datatypes of the columns\n",
        "df_pyspark.printSchema()\n",
        "\n",
        "#by default this considers all features as string values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBGNP77nQHVO",
        "outputId": "07ba4d77-3aca-4a7f-a103-f4059474ddab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#another way to read the dataframe\n",
        "df_pyspark= spark.read.csv('test1.csv', header= True, inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip4EFslWQuNv",
        "outputId": "327c81d2-041c-4c5e-9746-87bb9b5dda1f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#columns and selectiong columns"
      ],
      "metadata": {
        "id": "7c7UHujMVn2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2MaolHpSVln",
        "outputId": "8b5bfc4f-9e60-4a84-9ce3-83ccda74a496"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jrOuKlVfAp",
        "outputId": "7c38d6e6-40c3-4717-dfd0-194f3d139c33"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n",
              " Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000),\n",
              " Row(Name='Sunny', age=29, Experience=4, Salary=20000)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmTheEUxVhTS",
        "outputId": "1ba444a6-5cb0-4da4-b175-8e4a45818ee0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is selecting the column name\n",
        "df_pyspark.select('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIRzV4StVuJq",
        "outputId": "0b46c310-1b73-4c5f-e279-ad7c3684d873"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|     Name|\n",
            "+---------+\n",
            "|    Krish|\n",
            "|Sudhanshu|\n",
            "|    Sunny|\n",
            "|     Paul|\n",
            "|   Harsha|\n",
            "|  Shubham|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting multiple columns\n",
        "df_pyspark.select(['Name', 'Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv5WezzeVy9_",
        "outputId": "f399f55e-035b-4258-b347-106468a702ca"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|     Name|Experience|\n",
            "+---------+----------+\n",
            "|    Krish|        10|\n",
            "|Sudhanshu|         8|\n",
            "|    Sunny|         4|\n",
            "|     Paul|         3|\n",
            "|   Harsha|         1|\n",
            "|  Shubham|         2|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shows you data types\n",
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIWKXcwWV_0A",
        "outputId": "db4b43ba-3948-4959-d8b8-7a759ebb27cb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is like trhe describe in panadas and in this case the null is there because its a string\n",
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS8uKd4aWGjF",
        "outputId": "fd489d42-03db-4b7d-95e7-fa9ef9f8edb0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-----------------+------------------+\n",
            "|summary|  Name|               age|       Experience|            Salary|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "|  count|     6|                 6|                6|                 6|\n",
            "|   mean|  NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n",
            "| stddev|  NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
            "|    min|Harsha|                21|                1|             15000|\n",
            "|    max| Sunny|                31|               10|             30000|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding columns in a pyspark dataframe\n",
        "\n",
        "#basically adding the new columns plus two\n",
        "df_pyspark= df_pyspark.withColumn('Experience after 2 years',df_pyspark['Experience']+2)\n",
        "\n"
      ],
      "metadata": {
        "id": "aPR36xc_WX3D"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcyfEajBW52y",
        "outputId": "87877f52-e3b8-4f4c-9c7b-3bdda7599d54"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+------------------------+\n",
            "|     Name|age|Experience|Salary|Experience after 2 years|\n",
            "+---------+---+----------+------+------------------------+\n",
            "|    Krish| 31|        10| 30000|                      12|\n",
            "|Sudhanshu| 30|         8| 25000|                      10|\n",
            "|    Sunny| 29|         4| 20000|                       6|\n",
            "|     Paul| 24|         3| 20000|                       5|\n",
            "|   Harsha| 21|         1| 15000|                       3|\n",
            "|  Shubham| 23|         2| 18000|                       4|\n",
            "+---------+---+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping columns\n",
        "\n",
        "df_pyspark= df_pyspark.drop('Experience after 2 years')"
      ],
      "metadata": {
        "id": "5S7TClTPXSB6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XomK7iHvXbDL",
        "outputId": "3479a996-ffe6-4aa6-eca0-0113196b9576"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#renaming the column\n",
        "\n",
        "df_pyspark.withColumnRenamed('Name', 'New Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIUUyIhkXae-",
        "outputId": "6251914c-8f39-4578-8f4c-68277c09025e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "| New Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark handling Missing values"
      ],
      "metadata": {
        "id": "Ae6MFlTiXtBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark= SparkSession.builder.appName('Practise').getOrCreate()"
      ],
      "metadata": {
        "id": "dwBsxURGXksm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df= spark.read.option('header','true').csv('/content/test2.csv')\n",
        "new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0Tfrie0X-YS",
        "outputId": "d5367d26-b073-40fc-9a94-7fb363beaa7b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "|     NULL|  36|      NULL|  NULL|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the null values from rows\n",
        "\n",
        "new_df.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaMGx7XqX9kY",
        "outputId": "eacffcae-80f5-4a2b-8dde-fa03f45adaef"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# any== how\n",
        "#this bascilaly drops rows  that only has straight up null values leaving the other random nulls there\n",
        "new_df.na.drop(how=\"all\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JhUj3PtZejy",
        "outputId": "aeb9da16-2165-4976-9967-1e3b5cabdce8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "|     NULL|  36|      NULL|  NULL|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#any is the default value where it removes all null values\n",
        "\n",
        "new_df.na.drop(how=\"any\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md-7UpFhaE9c",
        "outputId": "ae4b5f65-ef60-4a89-e806-4b8205b633b1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#threshold , the last row was deleted , at least two non  null values gets deletrd\n",
        "new_df.na.drop(how=\"any\", thresh= 2).show()\n"
      ],
      "metadata": {
        "id": "M74eVYKPaY2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subset, is bascial;ly only dropping null values from a spefic column\n",
        "\n",
        "new_df.na.drop(how=\"any\",subset=['age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc1FBqlbRT-",
        "outputId": "27f4d8d9-c673-4021-edcc-002e1c785830"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     NULL| 34|        10| 38000|\n",
            "|     NULL| 36|      NULL|  NULL|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filling in the missing values\n",
        "#this fills in thre nulls with Missing value\n",
        "new_df.na.fill('Missing value').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J00b3yOHbjrH",
        "outputId": "6cb48f41-c6e1-4876-e2e4-f92503c60705"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+-------------+-------------+\n",
            "|         Name|          age|   Experience|       Salary|\n",
            "+-------------+-------------+-------------+-------------+\n",
            "|        Krish|           31|           10|        30000|\n",
            "|    Sudhanshu|           30|            8|        25000|\n",
            "|        Sunny|           29|            4|        20000|\n",
            "|         Paul|           24|            3|        20000|\n",
            "|       Harsha|           21|            1|        15000|\n",
            "|      Shubham|           23|            2|        18000|\n",
            "|       Mahesh|Missing value|Missing value|        40000|\n",
            "|Missing value|           34|           10|        38000|\n",
            "|Missing value|           36|Missing value|Missing value|\n",
            "+-------------+-------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is filling in the missing values in certain columns ['Name', 'Age'] with  Missing value\n",
        "new_df.na.fill('Missing value', ['Name', 'Age']).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG4l4CNCby3z",
        "outputId": "026f29ca-92aa-4776-a226-aceef14b4823"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+----------+------+\n",
            "|         Name|          age|Experience|Salary|\n",
            "+-------------+-------------+----------+------+\n",
            "|        Krish|           31|        10| 30000|\n",
            "|    Sudhanshu|           30|         8| 25000|\n",
            "|        Sunny|           29|         4| 20000|\n",
            "|         Paul|           24|         3| 20000|\n",
            "|       Harsha|           21|         1| 15000|\n",
            "|      Shubham|           23|         2| 18000|\n",
            "|       Mahesh|Missing value|      NULL| 40000|\n",
            "|Missing value|           34|        10| 38000|\n",
            "|Missing value|           36|      NULL|  NULL|\n",
            "+-------------+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvN-19kbb_v8",
        "outputId": "ca363a73-cad0-47d3-fc21-597045e8ca9f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'),\n",
              " ('age', 'string'),\n",
              " ('Experience', 'string'),\n",
              " ('Salary', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is cahning the data types of the columns\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "new_df= new_df\\\n",
        ".withColumn('age',\n",
        "            new_df['age']\n",
        "            .cast(FloatType()))\\\n",
        ".withColumn('Experience',\n",
        "            new_df['Experience']\n",
        "            .cast(FloatType()))\\\n",
        ".withColumn('Salary',\n",
        "            new_df['Salary']\n",
        "            .cast(FloatType()))\n",
        "\n",
        "new_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ISRyFVufOCQ",
        "outputId": "b43797ba-7b66-48a4-c1bb-e0c953d418d0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'),\n",
              " ('age', 'float'),\n",
              " ('Experience', 'float'),\n",
              " ('Salary', 'float')]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to fill in the null values with mean using the sk learn imputer function\n",
        "\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer= Imputer(\n",
        "    inputCols= ['age', 'Experience', 'Salary'],\n",
        "    outputCols=['{}_imputed'.format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"mean\")\n",
        "\n",
        "    #you can change the set strategy to mode , median"
      ],
      "metadata": {
        "id": "U6OLEr3ecOyD"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add imputation cols to df , you can see the columns with the _imputed\n",
        "\n",
        "imputer.fit(new_df).transform(new_df).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh89zlsKeS_C",
        "outputId": "21f5fdf9-ee2a-4e34-fde6-5c9bcf437b51"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+-------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience| Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+-------+-----------+------------------+--------------+\n",
            "|    Krish|31.0|      10.0|30000.0|       31.0|              10.0|       30000.0|\n",
            "|Sudhanshu|30.0|       8.0|25000.0|       30.0|               8.0|       25000.0|\n",
            "|    Sunny|29.0|       4.0|20000.0|       29.0|               4.0|       20000.0|\n",
            "|     Paul|24.0|       3.0|20000.0|       24.0|               3.0|       20000.0|\n",
            "|   Harsha|21.0|       1.0|15000.0|       21.0|               1.0|       15000.0|\n",
            "|  Shubham|23.0|       2.0|18000.0|       23.0|               2.0|       18000.0|\n",
            "|   Mahesh|NULL|      NULL|40000.0|       28.5|          5.428571|       40000.0|\n",
            "|     NULL|34.0|      10.0|38000.0|       34.0|              10.0|       38000.0|\n",
            "|     NULL|36.0|      NULL|   NULL|       36.0|          5.428571|       25750.0|\n",
            "+---------+----+----------+-------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32Y_WFYDczW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}