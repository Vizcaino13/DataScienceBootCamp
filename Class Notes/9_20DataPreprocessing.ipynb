{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78dBE8zO5L_l"
      },
      "outputs": [],
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing - preparing the data for certain things you will do to it/analysis. You preprocess it by  cleaning, transforming and combinin/ chaning it for the certain needs.\n",
        "\n",
        "Structured data which is data in rows and columns.\n",
        "\n",
        "Unstructured data- data not arranged in any format. It is very random.\n",
        "\n",
        "\n",
        "machine does not understand nonnumeric data, Unstructured data and structured data, so you have to make data machine readable.To make the data machine ready, you have to preprocess the data.\n",
        "\n",
        "Data Preprocessing is 60-80 percent of activity you preform for any algorithm, it is the most important thing. If not done correct then it will give spolied results. trash in and trash out, if you insert trash into your system then you will result in trash.\n",
        "\n",
        "feature engineering\n",
        "\n",
        "\n",
        "##1st thing in Data Preprocessing is selecting the librarys\n",
        "\n",
        "##2nd importing/selecting the data source\n",
        "\n",
        "##3nd work on missing data by using strategies(identify the columns, rows that are missing in the data and come up with a solution so that u are able to work on the value)\n",
        "\n",
        "##4th categorical data\n",
        "\n",
        "##5th identify dependent and indepent values- looking at the data and determining which data is which.\n",
        "\n",
        "##6th splitting the data into train and test sets(after a machine getting training of the certaing values then it has the training on it, and thae algorithm will be capable of handindling any type of situation 75-90 % data goes to training sets ,10-25% goes for test purpose\n",
        "\n",
        "##7th feature scaling - convert the data into one particular unit"
      ],
      "metadata": {
        "id": "B6FLPnl2Qi7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n",
        "\n",
        "##1.Feature Transformation\n",
        "*   a. **Missing Values**(myscilearn library doesnt work with missing values, best solution is to try to regain the values if its not NA(all columns are Null). Now how to handle that situation: discuss the missing vlaues woth domain experts/functional consultants)\n",
        "  * **Statistical Soultions/Strategies For Replacing Missing Values:** is average, median,most frequent values, constant so if you have age for example and there are null values, its best to find either the avg, or median of the dataset and fill in those null values with that.\n",
        "\n",
        "*   b. **Handling Categorical Features:** Categorical handling would be like lets say there are 3 countries Germany, Spain, France.you can create dummy columns to represent each category. This technique is known as one-hot encoding.\n",
        "*   c. **Outlier Dectection:** Its basically a value that is not like the other values. The value is out of expectation compared to the other values.\n",
        "*   d. **Feature Scaling:** -to make sure that different features (or variables) are on a similar scale or level playing field.  Feature scaling helps ensure that the algorithm doesn't give too much weight to one feature just because it has larger values. It allows the algorithm to focus on the relationship between features rather than their absolute values\n",
        "\n",
        "##2.Feature Construction\n",
        "\n",
        "\n",
        "\n",
        "##3.Feature Selection\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##4.Feature Selection"
      ],
      "metadata": {
        "id": "fN_SC54bXkVS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1zcUhTmXLQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqRH6Wrp9zTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}